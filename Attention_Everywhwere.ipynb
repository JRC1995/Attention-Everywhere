{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded GloVe!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from __future__ import division\n",
    "\n",
    "filename = 'glove.6B.50d.txt'\n",
    "def loadGloVe(filename):\n",
    "    vocab = []\n",
    "    embd = []\n",
    "    file = open(filename,'r')\n",
    "    for line in file.readlines():\n",
    "        row = line.strip().split(' ')\n",
    "        vocab.append(row[0])\n",
    "        embd.append(row[1:])\n",
    "    print('Loaded GloVe!')\n",
    "    file.close()\n",
    "    return vocab,embd\n",
    "vocab,embd = loadGloVe(filename)\n",
    "\n",
    "embedding = np.asarray(embd)\n",
    "embedding = embedding.astype(np.float32)\n",
    "\n",
    "word_vec_dim = len(embedding[0])\n",
    "#Pre-trained GloVe embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_nearest_neighbour(x):\n",
    "    #returns array in embedding that's most similar (in terms of cosine similarity) to x\n",
    "        \n",
    "    xdoty = np.multiply(embedding,x)\n",
    "    xdoty = np.sum(xdoty,1)\n",
    "    xlen = np.square(x)\n",
    "    xlen = np.sum(xlen,0)\n",
    "    xlen = np.sqrt(xlen)\n",
    "    ylen = np.square(embedding)\n",
    "    ylen = np.sum(ylen,1)\n",
    "    ylen = np.sqrt(ylen)\n",
    "    xlenylen = np.multiply(xlen,ylen)\n",
    "    cosine_similarities = np.divide(xdoty,xlenylen)\n",
    "\n",
    "    return embedding[np.argmax(cosine_similarities)]\n",
    "\n",
    "\n",
    "def word2vec(word):  # converts a given word into its vector representation\n",
    "    if word in vocab:\n",
    "        return embedding[vocab.index(word)]\n",
    "    else:\n",
    "        return embedding[vocab.index('unk')]\n",
    "\n",
    "def vec2word(vec):   # converts a given vector representation into the represented word \n",
    "    for x in xrange(0, len(embedding)):\n",
    "        if np.array_equal(embedding[x],np.asarray(vec)):\n",
    "            return vocab[x]\n",
    "    return vec2word(np_nearest_neighbour(np.asarray(vec)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open ('vec_summaries', 'rb') as fp:\n",
    "    vec_summaries = pickle.load(fp)\n",
    "\n",
    "with open ('vec_texts', 'rb') as fp:\n",
    "    vec_texts = pickle.load(fp)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('vocab_limit', 'rb') as fp:\n",
    "    vocab_limit = pickle.load(fp)\n",
    "\n",
    "with open ('embd_limit', 'rb') as fp:\n",
    "    embd_limit = pickle.load(fp)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_limit.append('<SOS>')\n",
    "embd_limit.append(np.zeros((word_vec_dim),dtype=np.float32))\n",
    "\n",
    "SOS = embd_limit[vocab_limit.index('<SOS>')]\n",
    "\n",
    "np_embd_limit = np.asarray(embd_limit,dtype=np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of dataset with summary length beyond 7: 16.146% \n",
      "Percentage of dataset with text length more than 80: 40.412% \n"
     ]
    }
   ],
   "source": [
    "#DIAGNOSIS\n",
    "\n",
    "count = 0\n",
    "\n",
    "LEN = 7\n",
    "\n",
    "for summary in vec_summaries:\n",
    "    if len(summary)-1>LEN:\n",
    "        count = count + 1\n",
    "print \"Percentage of dataset with summary length beyond \"+str(LEN)+\": \"+str((count/len(vec_summaries))*100)+\"% \"\n",
    "\n",
    "count = 0\n",
    "\n",
    "LEN = 80\n",
    "\n",
    "for text in vec_texts:\n",
    "    if len(text)>LEN:\n",
    "        count = count + 1\n",
    "print \"Percentage of dataset with text length more than \"+str(LEN)+\": \"+str((count/len(vec_texts))*100)+\"% \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SUMMARY_LEN = 7\n",
    "MAX_TEXT_LEN = 80\n",
    "\n",
    "#REMOVE DATA WHOSE SUMMARIES ARE TOO BIG\n",
    "#OR WHOSE TEXT LENGTH IS TOO BIG\n",
    "\n",
    "vec_summaries_reduced = []\n",
    "vec_texts_reduced = []\n",
    "\n",
    "i = 0\n",
    "for summary in vec_summaries:\n",
    "    if len(summary)-1<=MAX_SUMMARY_LEN and len(vec_texts[i])<=MAX_TEXT_LEN:\n",
    "        vec_summaries_reduced.append(summary)\n",
    "        vec_texts_reduced.append(vec_texts[i])\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_len = int((.7)*len(vec_summaries_reduced))\n",
    "\n",
    "train_texts = vec_texts_reduced[0:train_len]\n",
    "train_summaries = vec_summaries_reduced[0:train_len]\n",
    "\n",
    "val_len = int((.15)*len(vec_summaries_reduced))\n",
    "\n",
    "val_texts = vec_texts_reduced[train_len:train_len+val_len]\n",
    "val_summaries = vec_summaries_reduced[train_len:train_len+val_len]\n",
    "\n",
    "test_texts = vec_texts_reduced[train_len+val_len:len(vec_summaries_reduced)]\n",
    "test_summaries = vec_summaries_reduced[train_len+val_len:len(vec_summaries_reduced)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18858\n"
     ]
    }
   ],
   "source": [
    "print train_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_out(output_text):\n",
    "    output_len = len(output_text)\n",
    "    transformed_output = np.zeros([output_len],dtype=np.int32)\n",
    "    for i in xrange(0,output_len):\n",
    "        transformed_output[i] = vocab_limit.index(vec2word(output_text[i]))\n",
    "    #transformed_output[output_len:MAX_LEN] = vocab_limit.index('<PAD>')\n",
    "    return transformed_output   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some MORE hyperparameters and other stuffs\n",
    "\n",
    "hidden_size = 500\n",
    "learning_rate = 0.003\n",
    "vocab_len = len(vocab_limit)\n",
    "training_iters = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "#placeholders\n",
    "tf_text = tf.placeholder(tf.float32, [None,word_vec_dim])\n",
    "tf_seq_len = tf.placeholder(tf.int32)\n",
    "tf_summary = tf.placeholder(tf.int32,[None])\n",
    "tf_output_len = tf.placeholder(tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(hs,ht,seq_len):\n",
    "    return tf.reshape(tf.matmul(hs,tf.transpose(ht)),[seq_len])\n",
    "\n",
    "\n",
    "def align(hs,ht,seq_len):\n",
    "\n",
    "    G = tf.nn.softmax(score(hs,ht,seq_len))\n",
    "    G = tf.reshape(G,[seq_len,1])\n",
    "    \n",
    "    return G\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_encoder(x,seq_len,inp_dim):\n",
    "    \n",
    "    #PARAMETERS\n",
    "    \n",
    "    Wxh = tf.Variable(tf.truncated_normal(shape=[word_vec_dim,hidden_size],stddev=0.01))\n",
    "    Whh = tf.get_variable(name=\"whhf\",shape=[hidden_size,hidden_size],dtype=tf.float32,initializer=tf.orthogonal_initializer())\n",
    "    B = tf.Variable(tf.zeros([1,hidden_size]),dtype=tf.float32)\n",
    "    \n",
    "    Wc = tf.Variable(tf.truncated_normal(shape=[2*hidden_size,hidden_size],stddev=0.01))\n",
    "    \n",
    "    #CONSTANTS AND ARRAYS\n",
    "    hidden = tf.zeros([1,hidden_size],dtype=tf.float32)\n",
    "    hidden_list = tf.TensorArray(size=1,dynamic_size=True,dtype=tf.float32,clear_after_read=False)\n",
    "    forward_list = tf.TensorArray(size=seq_len,dtype=tf.float32)\n",
    "    context_vector = tf.zeros([1,hidden_size],dtype=tf.float32)\n",
    "    \n",
    "    #some initial operations\n",
    "    i = 0\n",
    "    inp = tf.reshape(x[i],[1,inp_dim])\n",
    "    inp_comp = tf.matmul(inp,Wxh)\n",
    "    \n",
    "    candidate_hidden = tf.nn.elu(inp_comp + tf.matmul(hidden,Whh) + B)\n",
    "                                 \n",
    "    attended_hidden = tf.tanh(tf.matmul(tf.concat([context_vector,candidate_hidden],1),Wc))\n",
    "                                 \n",
    "    hidden = attended_hidden\n",
    "    \n",
    "    hidden_list = hidden_list.write(i,tf.reshape(hidden,[hidden_size]))\n",
    "    forward_list = forward_list.write(i,tf.reshape(hidden,[hidden_size]))\n",
    "    \n",
    "    i = 1\n",
    "    \n",
    "    def cond(i,hidden,hidden_list,forward_list):\n",
    "        return i<seq_len\n",
    "    \n",
    "    def body(i,hidden,hidden_list,forward_list):\n",
    "        \n",
    "        hidden_list_stack = hidden_list.stack()\n",
    "        \n",
    "        inp = tf.reshape(x[i],[1,inp_dim])\n",
    "        inp_comp = tf.matmul(inp,Wxh)\n",
    "        \n",
    "        candidate_hidden = tf.nn.elu(inp_comp + tf.matmul(hidden,Whh) + B)\n",
    "        \n",
    "        G = align(hidden_list_stack,candidate_hidden,i)\n",
    "        \n",
    "        weighted_prev_hiddens = tf.multiply(hidden_list_stack,G)\n",
    "        context_vector = tf.reduce_sum(weighted_prev_hiddens,0)\n",
    "        context_vector = tf.reshape(context_vector,[1,hidden_size])\n",
    "        \n",
    "        attended_hidden = tf.tanh(tf.matmul(tf.concat([context_vector,candidate_hidden],1),Wc))\n",
    "        \n",
    "        hidden = attended_hidden\n",
    "\n",
    "        hidden_list = tf.cond(i<seq_len-1,\n",
    "                              lambda: hidden_list.write(i,tf.reshape(hidden,[hidden_size])),\n",
    "                              lambda: hidden_list)\n",
    "        forward_list = forward_list.write(i,tf.reshape(hidden,[hidden_size]))\n",
    "        \n",
    "        return i+1,hidden,hidden_list,forward_list\n",
    "    \n",
    "    _,_,hidden_list,forward_list = tf.while_loop(cond,body,[i,hidden,hidden_list,forward_list])\n",
    "    \n",
    "    hidden_list.close().mark_used()\n",
    "    \n",
    "    return forward_list.stack()\n",
    "                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_encoder(x,seq_len,inp_dim):\n",
    "    \n",
    "    #PARAMETERS\n",
    "    \n",
    "    Wxh = tf.Variable(tf.truncated_normal(shape=[word_vec_dim,hidden_size],stddev=0.01))\n",
    "    Whh = tf.get_variable(name=\"whhb\",shape=[hidden_size,hidden_size],dtype=tf.float32,initializer = tf.orthogonal_initializer())\n",
    "    Whh = tf.Variable(np.eye(hidden_size),dtype=tf.float32)\n",
    "    B = tf.Variable(tf.zeros([1,hidden_size]),dtype=tf.float32)\n",
    "    \n",
    "    Wc = tf.Variable(tf.truncated_normal(shape=[2*hidden_size,hidden_size],stddev=0.01))\n",
    "    \n",
    "    #CONSTANTS AND ARRAYS\n",
    "    hidden = tf.zeros([1,hidden_size],dtype=tf.float32)\n",
    "    hidden_list = tf.TensorArray(size=1,dynamic_size=True,dtype=tf.float32,clear_after_read=False)\n",
    "    hidden_list_ordered = tf.TensorArray(size=seq_len,dtype=tf.float32)\n",
    "    context_vector = tf.zeros([1,hidden_size],dtype=tf.float32)\n",
    "    \n",
    "    #some initial operations\n",
    "    i = seq_len-1\n",
    "    j = 0\n",
    "    inp = tf.reshape(x[i],[1,inp_dim])\n",
    "    inp_comp = tf.matmul(inp,Wxh)\n",
    "    \n",
    "    candidate_hidden = tf.nn.elu(inp_comp + tf.matmul(hidden,Whh) + B)\n",
    "                                 \n",
    "    attended_hidden = tf.tanh(tf.matmul(tf.concat([context_vector,candidate_hidden],1),Wc))\n",
    "                                 \n",
    "    hidden = attended_hidden\n",
    "    \n",
    "    hidden_list = hidden_list.write(j,tf.reshape(hidden,[hidden_size]))\n",
    "    hidden_list_ordered = hidden_list_ordered.write(i,tf.reshape(hidden,[hidden_size]))\n",
    "    \n",
    "    i = seq_len-2\n",
    "    j = 1\n",
    "    \n",
    "    def cond(i,j,hidden,hidden_list,hidden_list_ordered):\n",
    "        return i>-1\n",
    "    \n",
    "    def body(i,j,hidden,hidden_list,hidden_list_ordered):\n",
    "        \n",
    "        hidden_list_stack = hidden_list.stack()\n",
    "        \n",
    "        inp = tf.reshape(x[i],[1,inp_dim])\n",
    "        inp_comp = tf.matmul(inp,Wxh)\n",
    "        \n",
    "        candidate_hidden = tf.nn.elu(inp_comp + tf.matmul(hidden,Whh) + B)\n",
    "        \n",
    "        G = align(hidden_list_stack,candidate_hidden,j)\n",
    "        \n",
    "        weighted_prev_hiddens = tf.multiply(hidden_list_stack,G)\n",
    "        context_vector = tf.reduce_sum(weighted_prev_hiddens,0)\n",
    "        context_vector = tf.reshape(context_vector,[1,hidden_size])\n",
    "        \n",
    "        attended_hidden = tf.tanh(tf.matmul(tf.concat([context_vector,candidate_hidden],1),Wc))\n",
    "        \n",
    "        hidden = attended_hidden\n",
    "\n",
    "        hidden_list = tf.cond(j<seq_len-1,\n",
    "                              lambda: hidden_list.write(j,tf.reshape(hidden,[hidden_size])),\n",
    "                              lambda: hidden_list)\n",
    "        hidden_list_ordered = hidden_list_ordered.write(i,tf.reshape(hidden,[hidden_size]))\n",
    "        \n",
    "        return i-1,j+1,hidden,hidden_list,hidden_list_ordered\n",
    "    \n",
    "    _,_,_,hidden_list,hidden_list_ordered = tf.while_loop(cond,body,[i,j,hidden,hidden_list,hidden_list_ordered])\n",
    "\n",
    "    hidden_list.close().mark_used()\n",
    "    \n",
    "    return hidden_list_ordered.stack()\n",
    "                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(hidden_size,encoded_hidden,tf_seq_len,tf_output_len):\n",
    "    \n",
    "    #PARAMETERS\n",
    "    \n",
    "    Wyh = tf.Variable(tf.truncated_normal(shape=[word_vec_dim,hidden_size],stddev=0.01))\n",
    "    Whh = Whh = tf.get_variable(name=\"whho\",shape=[hidden_size,hidden_size],dtype=tf.float32,initializer = tf.orthogonal_initializer())\n",
    "    B = tf.zeros([1,hidden_size],dtype=tf.float32)\n",
    "    Wc = tf.Variable(tf.truncated_normal(shape=[2*hidden_size,hidden_size],stddev=0.01))\n",
    "    Wcl = tf.Variable(tf.truncated_normal(shape=[2*hidden_size,hidden_size],stddev=0.01))\n",
    "    Ws = tf.Variable(tf.truncated_normal(shape=[hidden_size,vocab_len],stddev=0.01))\n",
    "    \n",
    "    #other non-trainable values\n",
    "    hidden = encoded_hidden[0]\n",
    "    hidden = tf.reshape(hidden,[1,hidden_size])\n",
    "    \n",
    "    tf_embd_limit = tf.convert_to_tensor(np_embd_limit)\n",
    "    \n",
    "    hidden_list_d = tf.TensorArray(dtype=tf.float32,size=1,dynamic_size=True,clear_after_read=False)\n",
    "    output = tf.TensorArray(size=tf_output_len,dtype=tf.float32)\n",
    "    \n",
    "    decoder_context_vector = tf.zeros([1,hidden_size],dtype=tf.float32)\n",
    "    \n",
    "    i = 0\n",
    "    \n",
    "    y = SOS\n",
    "    y = tf.reshape(y,[1,word_vec_dim])\n",
    "    initial_hidden = [encoded_hidden[0]]\n",
    "    candidate_hidden = tf.nn.elu(tf.matmul(y,Wyh) + tf.matmul(initial_hidden,Whh) + B)\n",
    "    \n",
    "    attended_hidden = tf.tanh(tf.matmul(tf.concat([decoder_context_vector,candidate_hidden],1),Wc))\n",
    "    \n",
    "    hidden = attended_hidden\n",
    "    \n",
    "    hidden_list_d = hidden_list_d.write(i,tf.reshape(hidden,[hidden_size]))\n",
    "                                 \n",
    "    \n",
    "    def cond(i,hidden,hidden_list_d,output):\n",
    "        return i < tf_output_len\n",
    "    def body(i,hidden,hidden_list_d,output):\n",
    "        \n",
    "        G = align(encoded_hidden,hidden,tf_seq_len)\n",
    "        weighted_encoded_hiddens = tf.multiply(encoded_hidden,G)\n",
    "        encoder_context_vector = tf.reduce_sum(weighted_encoded_hiddens,0)\n",
    "        encoder_context_vector = tf.reshape(encoder_context_vector,[1,hidden_size])\n",
    "        layer_attended_hidden = tf.tanh(tf.matmul(tf.concat([encoder_context_vector,hidden],1),Wcl))\n",
    "        \n",
    "        y = tf.matmul(layer_attended_hidden,Ws)\n",
    "        output = output.write(i,tf.reshape(y,[vocab_len]))\n",
    "        y = tf.nn.softmax(y)\n",
    "        \n",
    "        y_index = tf.cast(tf.argmax(tf.reshape(y,[vocab_len])),tf.int32)\n",
    "        y = tf_embd_limit[y_index]\n",
    "        y = tf.reshape(y,[1,word_vec_dim])\n",
    "        \n",
    "        candidate_hidden = tf.nn.elu(tf.matmul(y,Wyh) + tf.matmul(hidden,Whh) + B)\n",
    "        \n",
    "        hidden_list_stack = hidden_list_d.stack()\n",
    "        \n",
    "        G_dec = align(hidden_list_stack,candidate_hidden,i+1)\n",
    "        \n",
    "        weighted_prev_hiddens = tf.multiply(hidden_list_stack,G_dec)\n",
    "        decoder_context_vector = tf.reduce_sum(weighted_prev_hiddens,0)\n",
    "        decoder_context_vector = tf.reshape(decoder_context_vector,[1,hidden_size])\n",
    "        \n",
    "        attended_hidden = tf.tanh(tf.matmul(tf.concat([decoder_context_vector,candidate_hidden],1),Wc))\n",
    "        \n",
    "        hidden = attended_hidden\n",
    "        \n",
    "        hidden_list_d = tf.cond(i<tf_output_len-1,\n",
    "                              lambda:hidden_list_d.write(i+1,tf.reshape(hidden,[hidden_size])),\n",
    "                              lambda:hidden_list_d)                         \n",
    "        \n",
    "        \n",
    "        return i+1,hidden,hidden_list_d,output\n",
    "    \n",
    "    _,_,hidden_list_d,output = tf.while_loop(cond,body,[i,hidden,hidden_list_d,output])\n",
    "    \n",
    "    #hidden_list_stack_write_all = hidden_list_d.stack()\n",
    "    hidden_list_d.close().mark_used()\n",
    "    \n",
    "    return output.stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(tf_text,tf_seq_len,tf_output_len):\n",
    "                               \n",
    "    forward_hidden = forward_encoder(tf_text,\n",
    "                                     tf_seq_len,\n",
    "                                     word_vec_dim)\n",
    "    \n",
    "    backward_hidden = backward_encoder(tf_text,\n",
    "                                       tf_seq_len,\n",
    "                                       word_vec_dim)\n",
    "    \n",
    "    encoded_hidden = tf.concat([forward_hidden,backward_hidden],1)\n",
    "    \n",
    "    output = decoder(2*hidden_size,\n",
    "                    encoded_hidden,\n",
    "                    tf_seq_len,\n",
    "                    tf_output_len)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(tf_text,tf_seq_len,tf_output_len)\n",
    "\n",
    "#OPTIMIZER\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=output, labels=tf_summary))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "#PREDICTION\n",
    "\n",
    "pred = tf.TensorArray(size=tf_output_len,dtype=tf.int32)\n",
    "\n",
    "i=0\n",
    "\n",
    "def cond_pred(i,pred):\n",
    "    return i<tf_output_len\n",
    "def body_pred(i,pred):\n",
    "    pred = pred.write(i,tf.cast(tf.argmax(output[i]),tf.int32))\n",
    "    return i+1,pred\n",
    "\n",
    "i,pred = tf.while_loop(cond_pred,body_pred,[i,pred]) \n",
    "\n",
    "prediction = pred.stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration: 0\n",
      "Training input sequence length: 51\n",
      "Training target outputs sequence length: 4\n",
      "\n",
      "TEXT:\n",
      "i have bought several of the vitality canned dog food products and have found them all to be of good quality. the product looks more like a stew than a processed meat and it smells better. my labrador is finicky and she appreciates this product better than most.\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "faculties solidly prison adobo\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "good quality dog food\n",
      "\n",
      "loss=10.3835\n",
      "\n",
      "Iteration: 1\n",
      "Training input sequence length: 37\n",
      "Training target outputs sequence length: 3\n",
      "\n",
      "TEXT:\n",
      "product arrived labeled as jumbo salted peanuts ... the peanuts were actually small sized unsalted. not sure if this was an error or if the vendor intended to represent the product as `` jumbo ''.\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "good quality quality\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "not as advertised\n",
      "\n",
      "loss=10.3822\n",
      "\n",
      "Iteration: 2\n",
      "Training input sequence length: 46\n",
      "Training target outputs sequence length: 2\n",
      "\n",
      "TEXT:\n",
      "if you are looking for the secret ingredient in robitussin i believe i have found it. i got this in addition to the root beer extract i ordered( which was good) and made some cherry soda. the flavor is very medicinal.\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "not as\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "cough medicine\n",
      "\n",
      "loss=10.4014\n",
      "\n",
      "Iteration: 3\n",
      "Training input sequence length: 32\n",
      "Training target outputs sequence length: 2\n",
      "\n",
      "TEXT:\n",
      "great taffy at a great price. there was a wide assortment of yummy taffy. delivery was very quick. if your a taffy lover, this is a deal.\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "cria medicine\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "great taffy\n",
      "\n",
      "loss=10.3046\n",
      "\n",
      "Iteration: 4\n",
      "Training input sequence length: 30\n",
      "Training target outputs sequence length: 4\n",
      "\n",
      "TEXT:\n",
      "this taffy is so good. it is very soft and chewy. the flavors are amazing. i would definitely recommend you buying it. very satisfying!!\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "great advertised great bf\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "wonderful, tasty taffy\n",
      "\n",
      "loss=10.8364\n",
      "\n",
      "Iteration: 5\n",
      "Training input sequence length: 29\n",
      "Training target outputs sequence length: 2\n",
      "\n",
      "TEXT:\n",
      "right now i 'm mostly just sprouting this so my cats can eat the grass. they love it. i rotate it around with wheatgrass and rye too\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "great advertised\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "yay barley\n",
      "\n",
      "loss=10.3247\n",
      "\n",
      "Iteration: 6\n",
      "Training input sequence length: 29\n",
      "Training target outputs sequence length: 3\n",
      "\n",
      "TEXT:\n",
      "this is a very healthy dog food. good for their digestion. also good for small puppies. my dog eats her required amount at every feeding.\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "great medicine great\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "healthy dog food\n",
      "\n",
      "loss=10.5757\n",
      "\n",
      "Iteration: 7\n",
      "Training input sequence length: 19\n",
      "Training target outputs sequence length: 4\n",
      "\n",
      "TEXT:\n",
      "good flavor! these came securely packed ... they were fresh and delicious! i love these twizzlers!\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "great medicine great medicine\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "fresh and greasy!\n",
      "\n",
      "loss=10.3834\n",
      "\n",
      "Iteration: 8\n",
      "Training input sequence length: 24\n",
      "Training target outputs sequence length: 4\n",
      "\n",
      "TEXT:\n",
      "the strawberry twizzlers are my guilty pleasure- yummy. six pounds will be around for a while with my son and i.\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "great medicine great medicine\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "strawberry twizzlers- yummy\n",
      "\n",
      "loss=10.4247\n",
      "\n",
      "Iteration: 9\n",
      "Training input sequence length: 45\n",
      "Training target outputs sequence length: 2\n",
      "\n",
      "TEXT:\n",
      "i love eating them and they are good for watching tv and looking at movies! it is not too sweet. i like to transfer them to a zip lock baggie so they stay fresh so i can take my time eating them.\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "great medicine\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "poor taste\n",
      "\n",
      "loss=10.4952\n",
      "\n",
      "Iteration: 10\n",
      "Training input sequence length: 28\n",
      "Training target outputs sequence length: 3\n",
      "\n",
      "TEXT:\n",
      "i am very satisfied with my unk purchase. i shared these with others and we have all enjoyed them. i will definitely be ordering more.\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "tasty medicine great\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "love it!\n",
      "\n",
      "loss=11.5027\n",
      "\n",
      "Iteration: 11\n",
      "Training input sequence length: 31\n",
      "Training target outputs sequence length: 3\n",
      "\n",
      "TEXT:\n",
      "candy was delivered very fast and was purchased at a reasonable price. i was home bound and unable to get to a store so this was perfect for me.\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "great dog great\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "home delivered unk\n",
      "\n",
      "loss=10.5603\n",
      "\n",
      "Iteration: 12\n",
      "Training input sequence length: 52\n",
      "Training target outputs sequence length: 2\n",
      "\n",
      "TEXT:\n",
      "my husband is a twizzlers addict. we 've bought these many times from amazon because we 're government employees living overseas and ca n't get them in the country we are assigned to. they 've always been fresh and tasty, packed well and arrive in a timely manner.\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "yay dog\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "always fresh\n",
      "\n",
      "loss=13.5953\n",
      "\n",
      "Iteration: 13\n",
      "Training input sequence length: 68\n",
      "Training target outputs sequence length: 1\n",
      "\n",
      "TEXT:\n",
      "i bought these for my husband who is currently overseas. he loves these, and apparently his staff likes them unk< br/> there are generous amounts of twizzlers in each 16-ounce bag, and this was well worth the price.< a unk '' http: unk ''> twizzlers, strawberry, 16-ounce bags( pack of 6)< unk>\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "taffy\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "twizzlers\n",
      "\n",
      "loss=13.09\n",
      "\n",
      "Iteration: 14\n",
      "Training input sequence length: 31\n",
      "Training target outputs sequence length: 3\n",
      "\n",
      "TEXT:\n",
      "i can remember buying this candy as a kid and the quality has n't dropped in all these years. still a superb product you wo n't be disappointed with.\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "healthy dog healthy\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "delicious product!\n",
      "\n",
      "loss=10.3746\n",
      "\n",
      "Iteration: 15\n",
      "Training input sequence length: 21\n",
      "Training target outputs sequence length: 1\n",
      "\n",
      "TEXT:\n",
      "i love this candy. after weight watchers i had to cut back but still have a craving for it.\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "healthy\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "twizzlers\n",
      "\n",
      "loss=11.5616\n",
      "\n",
      "Iteration: 16\n",
      "Training input sequence length: 72\n",
      "Training target outputs sequence length: 7\n",
      "\n",
      "TEXT:\n",
      "i have lived out of the us for over 7 yrs now, and i so miss my twizzlers!! when i go back to visit or someone visits me, i always stock up. all i can say is yum!< br/> sell these in mexico and you will have a faithful buyer, more often than i 'm able to buy them right now.\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "dog greasy dog greasy dog greasy dog\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "please sell these in mexico!!\n",
      "\n",
      "loss=10.7537\n",
      "\n",
      "Iteration: 17\n",
      "Training input sequence length: 36\n",
      "Training target outputs sequence length: 3\n",
      "\n",
      "TEXT:\n",
      "product received is as unk< br/>< br/>< a unk '' http: unk ''> twizzlers, strawberry, 16-ounce bags( pack of 6)< unk>\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "dog home dog\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "twizzlers- strawberry\n",
      "\n",
      "loss=11.9005\n",
      "\n",
      "Iteration: 18\n",
      "Training input sequence length: 20\n",
      "Training target outputs sequence length: 3\n",
      "\n",
      "TEXT:\n",
      "the candy is just red, no flavor. just plan and chewy. i would never buy them again\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "dog- dog\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "nasty no flavor\n",
      "\n",
      "loss=10.6441\n",
      "\n",
      "Iteration: 19\n",
      "Training input sequence length: 43\n",
      "Training target outputs sequence length: 5\n",
      "\n",
      "TEXT:\n",
      "i was so glad amazon carried these batteries. i have a hard time finding them elsewhere because they are such a unique size. i need them for my garage door unk< br/> great deal for the price.\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "- dog- dog-\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "great bargain for the price\n",
      "\n",
      "loss=9.67069\n",
      "\n",
      "Iteration: 20\n",
      "Training input sequence length: 26\n",
      "Training target outputs sequence length: 5\n",
      "\n",
      "TEXT:\n",
      "this offer is a great price and a great taste, thanks amazon for selling this unk< br/>< br/> unk\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "- mexico- mexico-\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "this is my taste ...\n",
      "\n",
      "loss=9.94344\n",
      "\n",
      "Iteration: 21\n",
      "Training input sequence length: 60\n",
      "Training target outputs sequence length: 7\n",
      "\n",
      "TEXT:\n",
      "for those of us with celiac disease this product is a lifesaver and what could be better than getting it at almost half the price of the grocery or health food store! i love mccann 's instant oatmeal- all flavors!!!< br/>< br/> thanks,< br/> abby\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "- mexico- mexico- mexico-\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "love gluten free oatmeal!!!\n",
      "\n",
      "loss=8.98545\n",
      "\n",
      "Iteration: 22\n",
      "Training input sequence length: 59\n",
      "Training target outputs sequence length: 3\n",
      "\n",
      "TEXT:\n",
      "what else do you need to know? oatmeal, instant( make it with a half cup of low-fat milk and add raisins; nuke for 90 seconds). more expensive than kroger store brand oatmeal and maybe a little tastier or better texture or something. it 's still just oatmeal. mmm, convenient!\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "- mexico-\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "it 's oatmeal\n",
      "\n",
      "loss=12.6434\n",
      "\n",
      "Iteration: 23\n",
      "Training input sequence length: 79\n",
      "Training target outputs sequence length: 4\n",
      "\n",
      "TEXT:\n",
      "i ordered this for my wife as it was unk by our daughter. she has this almost every morning and likes all flavors. she 's happy, i 'm happy!!!< br/>< a unk '' http: unk ''> mccann 's instant irish oatmeal, variety pack of regular, apples& cinnamon, and maple& brown sugar, 10-count boxes( pack of 6)< unk>\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "delicious mexico delicious mexico\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "wife 's favorite breakfast\n",
      "\n",
      "loss=10.2244\n",
      "\n",
      "Iteration: 24\n",
      "Training input sequence length: 38\n",
      "Training target outputs sequence length: 1\n",
      "\n",
      "TEXT:\n",
      "i have mccann 's oatmeal every morning and by ordering it from amazon i am able to save almost$ 3.00 per unk< br/> it is a great product. tastes great and very healthy\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "flavor\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "unk\n",
      "\n",
      "loss=16.3472\n",
      "\n",
      "Iteration: 25\n",
      "Training input sequence length: 41\n",
      "Training target outputs sequence length: 3\n",
      "\n",
      "TEXT:\n",
      "mccann 's oatmeal is a good quality choice. our favorite is the apples and cinnamon, but we find that none of these are overly sugary. for a good hot breakfast in 2 minutes, this is excellent.\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "! flavor!\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "good hot breakfast\n",
      "\n",
      "loss=11.6994\n",
      "\n",
      "Iteration: 26\n",
      "Training input sequence length: 55\n",
      "Training target outputs sequence length: 4\n",
      "\n",
      "TEXT:\n",
      "we really like the mccann 's steel cut oats but find we do n't cook it up too unk< br/> this tastes much better to me than the grocery store brands and is just as unk< br/> anything that keeps me eating oatmeal regularly is a good thing.\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "! nasty! nasty\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "great taste and convenience\n",
      "\n",
      "loss=8.57626\n",
      "\n",
      "Iteration: 27\n",
      "Training input sequence length: 46\n",
      "Training target outputs sequence length: 2\n",
      "\n",
      "TEXT:\n",
      "this seems a little more wholesome than some of the supermarket brands, but it is somewhat mushy and does n't have quite as much flavor either. it did n't pass muster with my kids, so i probably wo n't buy it again.\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "'s!\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "hearty oatmeal\n",
      "\n",
      "loss=9.97795\n",
      "\n",
      "Iteration: 28\n",
      "Training input sequence length: 52\n",
      "Training target outputs sequence length: 1\n",
      "\n",
      "TEXT:\n",
      "good oatmeal. i like the apple cinnamon the best. though i would n't follow the directions on the package since it always comes out too soupy for my taste. that could just be me since i like my oatmeal really thick to add some milk on top of.\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "'s\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "good\n",
      "\n",
      "loss=15.7811\n",
      "\n",
      "Iteration: 29\n",
      "Training input sequence length: 25\n",
      "Training target outputs sequence length: 1\n",
      "\n",
      "TEXT:\n",
      "the flavors are good. however, i do not see any unk between this and unk oats brand- they are both mushy.\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "!\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "mushy\n",
      "\n",
      "loss=10.9426\n",
      "\n",
      "Iteration: 30\n",
      "Training input sequence length: 41\n",
      "Training target outputs sequence length: 2\n",
      "\n",
      "TEXT:\n",
      "this is the same stuff you can buy at the big box stores. there is nothing healthy about it. it is just carbs and sugars. save your money and get something that at least has some taste.\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "! 's\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "same stuff\n",
      "\n",
      "loss=11.0819\n",
      "\n",
      "Iteration: 31\n",
      "Training input sequence length: 25\n",
      "Training target outputs sequence length: 4\n",
      "\n",
      "TEXT:\n",
      "this oatmeal is not good. its mushy, soft, i do n't like it. quaker oats is the way to go.\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "great 's great 's\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "do n't like it\n",
      "\n",
      "loss=11.314\n",
      "\n",
      "Iteration: 32\n",
      "Training input sequence length: 37\n",
      "Training target outputs sequence length: 3\n",
      "\n",
      "TEXT:\n",
      "we 're used to spicy foods down here in south texas and these are not at all spicy. doubt very much habanero is used at all. could take it up a notch or two.\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "great taste great\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "not ass kickin\n",
      "\n",
      "loss=10.9876\n",
      "\n",
      "Iteration: 33\n",
      "Training input sequence length: 80\n",
      "Training target outputs sequence length: 5\n",
      "\n",
      "TEXT:\n",
      "i roast at home with a unk popcorn popper( but i do it outside, of course). these beans( coffee bean direct green mexican altura) seem to be well-suited for this method. the first and second cracks are distinct, and i 've roasted the beans from medium to slightly dark with great results every time. the aroma is strong and persistent. the taste is smooth, velvety, yet lively.\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "taste oatmeal taste oatmeal taste\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "roasts up a smooth brew\n",
      "\n",
      "loss=10.9797\n",
      "\n",
      "Iteration: 34\n",
      "Training input sequence length: 69\n",
      "Training target outputs sequence length: 5\n",
      "\n",
      "TEXT:\n",
      "we roast these in a large cast iron pan on the grill( about 1/3 of the bag at a time). the smell is wonderful and the roasted beans taste delicious too. more importantly, the coffee is smooth; no bitter aftertaste. on numerous occasions, we 've had to send the roasted beans home with friends because they like it so much.\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "oatmeal hot oatmeal hot oatmeal\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "our guests love it!\n",
      "\n",
      "loss=8.38702\n",
      "\n",
      "Iteration: 35\n",
      "Training input sequence length: 38\n",
      "Training target outputs sequence length: 3\n",
      "\n",
      "TEXT:\n",
      "deal was awesome! arrived before halloween as indicated and was enough to satisfy trick or treaters. i love the quality of this product and it was much less expensive than the local store 's candy.\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "hearty oatmeal hearty\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "awesome deal!\n",
      "\n",
      "loss=13.4931\n",
      "\n",
      "Iteration: 36\n",
      "Training input sequence length: 40\n",
      "Training target outputs sequence length: 6\n",
      "\n",
      "TEXT:\n",
      "it is chocolate, what can i say. great variety of everything our family loves. with a family of six it goes fast here. perfect variety. kit kat, unk, take five and more.\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "hearty oatmeal hearty oatmeal hearty oatmeal\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "how can you go wrong!\n",
      "\n",
      "loss=9.77891\n",
      "\n",
      "Iteration: 37\n",
      "Training input sequence length: 26\n",
      "Training target outputs sequence length: 3\n",
      "\n",
      "TEXT:\n",
      "halloween is over but, i sent a bag to my daughters class for her share. the chocolate was fresh and enjoyed by many.\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "hearty mushy hearty\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "great deal.\n",
      "\n",
      "loss=12.4916\n",
      "\n",
      "Iteration: 38\n",
      "Training input sequence length: 38\n",
      "Training target outputs sequence length: 6\n",
      "\n",
      "TEXT:\n",
      "watch your prices with this. while the assortment was good, and i did get this on a gold box purchase, the price for this was< br/>$ 3-4 less at target.\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "stuff mushy stuff mushy stuff mushy\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "better price for this at target\n",
      "\n",
      "loss=10.492\n",
      "\n",
      "Iteration: 39\n",
      "Training input sequence length: 33\n",
      "Training target outputs sequence length: 2\n",
      "\n",
      "TEXT:\n",
      "this bag of candy online is pretty expensive, it should be cheaper in order to compete with grocery stores, other than that, its a good combination of my favorite candy\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "mushy stuff\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "pretty expensive\n",
      "\n",
      "loss=11.596\n",
      "\n",
      "Iteration: 40\n",
      "Training input sequence length: 19\n",
      "Training target outputs sequence length: 3\n",
      "\n",
      "TEXT:\n",
      "arrived in 6 days and were so stale i could not eat any of the 6 bags!!\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "mushy ass mushy\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "stale product.\n",
      "\n",
      "loss=11.3971\n",
      "\n",
      "Iteration: 41\n",
      "Training input sequence length: 64\n",
      "Training target outputs sequence length: 4\n",
      "\n",
      "TEXT:\n",
      "this product serves me well as a source of electrolytes during and after a long run or bike unk< br/> i have tried all of the flavors but really do like the grapefruit flavor ... no unk and i actually like the slight unk< br/> i use other hammer products and really like their whole product line.\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "ass deal ass deal\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "great source of electrolytes\n",
      "\n",
      "loss=11.7888\n",
      "\n",
      "Iteration: 42\n",
      "Training input sequence length: 36\n",
      "Training target outputs sequence length: 4\n",
      "\n",
      "TEXT:\n",
      "this stuff really works for preventing cramping during the middle to latter stages of your rides. pop 1 into each water bottle and you 're set. flavor is fine and goes down easy.\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "awesome deal awesome deal\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "great for preventing cramps\n",
      "\n",
      "loss=11.6805\n",
      "\n",
      "Iteration: 43\n",
      "Training input sequence length: 19\n",
      "Training target outputs sequence length: 3\n",
      "\n",
      "TEXT:\n",
      "this was sooooo unk but too bad i ate em too fast and gained 2 pds! my fault\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "deal awesome deal\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "pretzel haven!\n",
      "\n",
      "loss=10.6469\n",
      "\n",
      "Iteration: 44\n",
      "Training input sequence length: 16\n",
      "Training target outputs sequence length: 2\n",
      "\n",
      "TEXT:\n",
      "it is okay. i would not go out of my way to buy it again\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "awesome deal\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "nothing special\n",
      "\n",
      "loss=11.7556\n",
      "\n",
      "Iteration: 45\n",
      "Training input sequence length: 23\n",
      "Training target outputs sequence length: 3\n",
      "\n",
      "TEXT:\n",
      "no tea flavor at all. just whole brunch of unk flavors. it is not returnable. i wasted unk bucks.\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "deal product deal\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "no tea flavor\n",
      "\n",
      "loss=11.9428\n",
      "\n",
      "Iteration: 46\n",
      "Training input sequence length: 67\n",
      "Training target outputs sequence length: 2\n",
      "\n",
      "TEXT:\n",
      "these taste really good. i have been purchasing a different brand and these are very similar in taste and texture. i agree with the other reviewer regarding ordering in the summer. there is no insulating packaging with ice packs so they will melt in warm weather like all chocolate food items. order in cold weather and buy enough to last!!!\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "pretty product\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "taste great\n",
      "\n",
      "loss=10.9815\n",
      "\n",
      "Iteration: 47\n",
      "Training input sequence length: 28\n",
      "Training target outputs sequence length: 5\n",
      "\n",
      "TEXT:\n",
      "the taste was great, but the berries had melted. may order again in winter. if you order in cold weather you should enjoy flavor.\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "great pretty great pretty great\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "order only in cold weather\n",
      "\n",
      "loss=12.2047\n",
      "\n",
      "Iteration: 48\n",
      "Training input sequence length: 39\n",
      "Training target outputs sequence length: 4\n",
      "\n",
      "TEXT:\n",
      "i know i can not make tea this good. granted, i am not from the south but i know i have never enjoyed tea that was this sweet without being too sweet. it tastes crisp.\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "pretty great pretty great\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "this is the best\n",
      "\n",
      "loss=10.008\n",
      "\n",
      "Iteration: 49\n",
      "Training input sequence length: 41\n",
      "Training target outputs sequence length: 2\n",
      "\n",
      "TEXT:\n",
      "this peppermint stick is delicious and fun to eat. my dad got me one for christmas because he remembered me having a similar one when i was a little girl. i 'm 30 now and i love it!\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "stale great\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "delicious!\n",
      "\n",
      "loss=14.8666\n",
      "\n",
      "Iteration: 50\n",
      "Training input sequence length: 29\n",
      "Training target outputs sequence length: 1\n",
      "\n",
      "TEXT:\n",
      "great gift for all ages! i purchased these giant canes before and the recipients loved them so much, they kept them and would not eat them.\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "this\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "great\n",
      "\n",
      "loss=24.6893\n",
      "\n",
      "Iteration: 51\n",
      "Training input sequence length: 77\n",
      "Training target outputs sequence length: 4\n",
      "\n",
      "TEXT:\n",
      "awesome dog food. however, when given to my `` boston '', who has severe reactions to some food ingredients; his itching increased to violent jumping out of bed at night, scratching. as soon as i changed to a different formula, the scratching stopped. so glad natural balance has other choices. i guess you have to try each, until you find what 's best for your pet.\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "this great this great\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "increased my dogs itching\n",
      "\n",
      "loss=12.9676\n",
      "\n",
      "Iteration: 52\n",
      "Training input sequence length: 56\n",
      "Training target outputs sequence length: 3\n",
      "\n",
      "TEXT:\n",
      "we have three dogs and all of them love this food! we bought it specifically for one of our dogs who has food allergies and it works great for him, no more hot spots or tummy unk< br/> i love that it ships right to our door with free shipping.\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "nothing special nothing\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "great food!\n",
      "\n",
      "loss=11.0891\n",
      "\n",
      "Iteration: 53\n",
      "Training input sequence length: 42\n",
      "Training target outputs sequence length: 5\n",
      "\n",
      "TEXT:\n",
      "my unk mix has ibs. our vet recommended a limited ingredient food. this has really helped her symptoms and she likes it. i will always buy it from amazon ... it 's$ 10 cheaper and free shipping!\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "nothing special nothing special nothing\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "great for stomach problems!\n",
      "\n",
      "loss=10.3641\n",
      "\n",
      "Iteration: 54\n",
      "Training input sequence length: 58\n",
      "Training target outputs sequence length: 2\n",
      "\n",
      "TEXT:\n",
      "great food! i love the idea of one food for all ages& breeds. t 's a real convenience as well as a really good product. my 3 dogs eat less, have almost no gas, their poop is regular and a perfect consistency, what else can a mom ask for!!\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "nothing special\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "great food\n",
      "\n",
      "loss=6.2937\n",
      "\n",
      "Iteration: 55\n",
      "Training input sequence length: 24\n",
      "Training target outputs sequence length: 3\n",
      "\n",
      "TEXT:\n",
      "this is great dog food, my dog has severs allergies and this brand is the only one that we can feed him.\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "best delicious best\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "great dog food\n",
      "\n",
      "loss=11.5595\n",
      "\n",
      "Iteration: 56\n",
      "Training input sequence length: 43\n",
      "Training target outputs sequence length: 4\n",
      "\n",
      "TEXT:\n",
      "this food is great- all ages dogs. i have a 3 year old and a puppy. they are both so soft and hardly ever get sick. the food is good especially when you have amazon prime shipping:)\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "delicious is delicious is\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "mmmmm mmmmm good.\n",
      "\n",
      "loss=13.4632\n",
      "\n",
      "Iteration: 57\n",
      "Training input sequence length: 28\n",
      "Training target outputs sequence length: 2\n",
      "\n",
      "TEXT:\n",
      "this is the same food we get at pet store. but it 's delivered to my door! and for the same price or slightly less.\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "great delicious\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "so convenient\n",
      "\n",
      "loss=11.7127\n",
      "\n",
      "Iteration: 58\n",
      "Training input sequence length: 67\n",
      "Training target outputs sequence length: 4\n",
      "\n",
      "TEXT:\n",
      "i 've been very pleased with the natural balance dog food. our dogs have had issues with other dog foods in the past and i had someone recommend natural balance grain free since it is possible they were allergic to grains. since switching i have n't had any issues. it is also helpful that have have different kibble size for unk sized dogs.\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "increased itching increased itching\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "good healthy dog food\n",
      "\n",
      "loss=14.3615\n",
      "\n",
      "Iteration: 59\n",
      "Training input sequence length: 43\n",
      "Training target outputs sequence length: 1\n",
      "\n",
      "TEXT:\n",
      "i fed this to my golden retriever and he hated it. he would n't eat it, and when he did, it gave him terrible diarrhea. we will not be buying this again. it 's also super expensive.\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "dogs\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "bad\n",
      "\n",
      "loss=11.8139\n",
      "\n",
      "Iteration: 60\n",
      "Training input sequence length: 24\n",
      "Training target outputs sequence length: 2\n",
      "\n",
      "TEXT:\n",
      "arrived slightly thawed. my parents would n't accept it. however, the company was very helpful and issued a full refund.\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "great for\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "great support\n",
      "\n",
      "loss=6.23135\n",
      "\n",
      "Iteration: 61\n",
      "Training input sequence length: 56\n",
      "Training target outputs sequence length: 2\n",
      "\n",
      "TEXT:\n",
      "the crust on these tarts are perfect. my husband loves these, but i 'm not so crazy about them. they are just too unk for my taste. i 'll eat the crust and hubby takes my filling. my kids think they 're great, so maybe it 's just me.\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "great for\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "tart!\n",
      "\n",
      "loss=13.6781\n",
      "\n",
      "Iteration: 62\n",
      "Training input sequence length: 39\n",
      "Training target outputs sequence length: 3\n",
      "\n",
      "TEXT:\n",
      "these are absolutely unk! my husband and i both love them, however, as another customer put it, they are expensive to ship! the cost of shipping is more than the tartlets themselves are!\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "dog great dog\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "omaha apple tartlets\n",
      "\n",
      "loss=11.5049\n",
      "\n",
      "Iteration: 63\n",
      "Training input sequence length: 37\n",
      "Training target outputs sequence length: 3\n",
      "\n",
      "TEXT:\n",
      "what a nice alternative to an apple pie. love the fact there was no slicing and dicing. easy to prepare. i also loved the fact that you can make them fresh whenever needed.\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "dog great dog\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "loved these tartlets\n",
      "\n",
      "loss=11.0166\n",
      "\n",
      "Iteration: 64\n",
      "Training input sequence length: 58\n",
      "Training target outputs sequence length: 2\n",
      "\n",
      "TEXT:\n",
      "i like creme brulee. i loved that these were so easy. just sprinkle on the sugar that came with and broil. they look amazing and taste great. my guess thought i really went out of the way for them when really it took all of 5 minutes. i will be ordering more!\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "so dog\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "the best\n",
      "\n",
      "loss=16.844\n",
      "\n",
      "Iteration: 65\n",
      "Training input sequence length: 17\n",
      "Training target outputs sequence length: 1\n",
      "\n",
      "TEXT:\n",
      "not what i was expecting in terms of the company 's reputation for excellent home delivery products\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "bad\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "disappointing\n",
      "\n",
      "loss=12.8173\n",
      "\n",
      "Iteration: 66\n",
      "Training input sequence length: 63\n",
      "Training target outputs sequence length: 2\n",
      "\n",
      "TEXT:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i love asparagus. up until very recently, i had never had pickled asparagus. oh my goodness, when a friend introduced me to this exact brand, i could n't believe how great stuff tasted. i loved it so much i bought the six pack. i 've got 2 jars left. gon na need more!!\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "bad so\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "asparagus bliss\n",
      "\n",
      "loss=12.1205\n",
      "\n",
      "Iteration: 67\n",
      "Training input sequence length: 33\n",
      "Training target outputs sequence length: 5\n",
      "\n",
      "TEXT:\n",
      "i was unk in the flavor and texture of this mix. i usually like most of the low carb things i have tried, but was unk in this specific one.\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "tartlets tart tartlets tart tartlets\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "low carb angel food puffs\n",
      "\n",
      "loss=14.2106\n",
      "\n",
      "Iteration: 68\n",
      "Training input sequence length: 60\n",
      "Training target outputs sequence length: 2\n",
      "\n",
      "TEXT:\n",
      "i have been drinking this tea for a long time now. i used to have to purchase it at a doctor 's office because it was n't available elsewhere. i 'm so glad that i can buy it now from amazon.com. i drink this tea throughout the day like other folks drink coffee. wonderful taste.\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "tart tartlets\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "delicious tea\n",
      "\n",
      "loss=13.2821\n",
      "\n",
      "Iteration: 69\n",
      "Training input sequence length: 65\n",
      "Training target outputs sequence length: 2\n",
      "\n",
      "TEXT:\n",
      "i love, love this green tea. it is very hard to find in our area and some places on the internet charge a big price and i usually do n't get as many boxes as i did with this merchant. i will definitely order from this seller again!! thanks!! i depend on my green tea fix everyday!\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "omaha apple\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "tea review\n",
      "\n",
      "loss=11.5681\n",
      "\n",
      "Iteration: 70\n",
      "Training input sequence length: 26\n",
      "Training target outputs sequence length: 2\n",
      "\n",
      "TEXT:\n",
      "i love this tea. it helps curb my eating during the day. my mom and i have given it all friends to try.\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "tart loved\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "wonderful tea\n",
      "\n",
      "loss=8.90763\n",
      "\n",
      "Iteration: 71\n",
      "Training input sequence length: 47\n",
      "Training target outputs sequence length: 2\n",
      "\n",
      "TEXT:\n",
      "i 'm italian and i lived in italy for years. i used to buy these cookies for my everyday breakfast with an italian espresso. i could n't find them anywhere here in the bay area, so it 's great to have them again.\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "loved these\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "great cookies\n",
      "\n",
      "loss=15.5236\n",
      "\n",
      "Iteration: 72\n",
      "Training input sequence length: 79\n",
      "Training target outputs sequence length: 3\n",
      "\n",
      "TEXT:\n",
      "i have done a lot of research to find the best food for my cat, and this is an excellent food. that is also according to my holistic veterinarian. they put probiotics on the kibble as the last step, which is very important to me. the best thing is that my cat loved it immediately and i had to stop mixing it with the old food because she only would eat holistic select.\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "disappointing bliss disappointing\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "great food.\n",
      "\n",
      "loss=17.9943\n",
      "\n",
      "Iteration: 73\n",
      "Training input sequence length: 65\n",
      "Training target outputs sequence length: 7\n",
      "\n",
      "TEXT:\n",
      "one of my cats is allergic to fish and beef. this formula is one of the few she can eat, and it has much better ingredients than the prescription diets available at the vet. both of my kitties are very active, have soft shiny fur, and neither are fat. dry food reduces tartar buildup on teeth, also.\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "tea bliss tea bliss tea bliss tea\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "wonderful food- perfect for allergic kitties\n",
      "\n",
      "loss=14.0556\n",
      "\n",
      "Iteration: 74\n",
      "Training input sequence length: 51\n",
      "Training target outputs sequence length: 4\n",
      "\n",
      "TEXT:\n",
      "our cats thrive extremely well on this dry cat food. they definitely have much less hair ball throw ups and their fur is great. they are fit and not over weight. this vendor ships extremely fast. is one of the top amazon suppliers in our book!\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "tea review tea review\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "holistic select cat food\n",
      "\n",
      "loss=13.041\n",
      "\n",
      "Iteration: 75\n",
      "Training input sequence length: 45\n",
      "Training target outputs sequence length: 3\n",
      "\n",
      "TEXT:\n",
      "i 've been eating ramen noodles since i was a little kid, and i 've never found a better flavor than hot& spicy chicken! it is n't hot at all to a unk like me, but it sure is good!\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "tea review tea\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "my favorite ramen\n",
      "\n",
      "loss=16.3813\n",
      "\n",
      "Iteration: 76\n",
      "Training input sequence length: 54\n",
      "Training target outputs sequence length: 3\n",
      "\n",
      "TEXT:\n",
      "i love spicy ramen, but for whatever reasons this thing burns my stomach badly and the burning sensation does n't go away for like 3 hours! not sure if that is healthy or not .... and you can buy this at walmart for$ 0.28, way cheaper than amazon.\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "review tea review\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "it burns!\n",
      "\n",
      "loss=10.7485\n",
      "\n",
      "Iteration: 77\n",
      "Training input sequence length: 42\n",
      "Training target outputs sequence length: 6\n",
      "\n",
      "TEXT:\n",
      "always being a fan of ramen as a quick and easy meal, finding it on amazon for a decent price and having it delivered to your door by the case is an amazing situation for anyone to find themselves in.\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "cookies tea cookies tea cookies tea\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "amazing to the last bite.\n",
      "\n",
      "loss=11.9274\n",
      "\n",
      "Iteration: 78\n",
      "Training input sequence length: 56\n",
      "Training target outputs sequence length: 3\n",
      "\n",
      "TEXT:\n",
      "i must be a bit of a wuss, because this soup tastes to me how i imagine fire might taste. typically i like spicy food if it has a good flavor. i do n't find this to be the case with this soup. any flavor is killed off by the burn.\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "cookies best cookies\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "not for me\n",
      "\n",
      "loss=13.3874\n",
      "\n",
      "Iteration: 79\n",
      "Training input sequence length: 50\n",
      "Training target outputs sequence length: 3\n",
      "\n",
      "TEXT:\n",
      "i really loved the spicy flavor these had. i found myself liking the broth more than the noodles which is usually the opposite. if you are n't used to the heat this might bother you and if you like hot hot foods this might not be enough.\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "delicious best delicious\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "great spicy flavor\n",
      "\n",
      "loss=12.9735\n",
      "\n",
      "Iteration: 80\n",
      "Training input sequence length: 78\n",
      "Training target outputs sequence length: 5\n",
      "\n",
      "TEXT:\n",
      "got these on sale for roughly 25 cents per cup, which is half the price of my local grocery stores, plus they rarely stock the spicy flavors. these things are a great snack for my office where time is constantly crunched and sometimes you ca n't escape for a real meal. this is one of my favorite flavors of instant lunch and will be back to buy every time it goes on sale.\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "select holistic select holistic select\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "great value and convenient ramen\n",
      "\n",
      "loss=14.9474\n",
      "\n",
      "Iteration: 81\n",
      "Training input sequence length: 22\n",
      "Training target outputs sequence length: 2\n",
      "\n",
      "TEXT:\n",
      "i have bought allot of different flavors and this happens to be one of my favorites and will be getting more soon\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "food holistic\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "great flavor\n",
      "\n",
      "loss=12.4559\n",
      "\n",
      "Iteration: 82\n",
      "Training input sequence length: 74\n",
      "Training target outputs sequence length: 5\n",
      "\n",
      "TEXT:\n",
      "the best investment i 've ever made for ginger. it 's unbelievable! it 's fibrous like the real ginger, has that spicy kick to it, but it 's perfect with the sugar- calms it down. it 's very worth the$ 40 for unk of it! i 'll be getting more soon- i use these as a topper for my ginger cupcakes and cookies:)\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "food burns food burns food\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "tastes awesome& looks beautiful\n",
      "\n",
      "loss=13.1607\n",
      "\n",
      "Iteration: 83\n",
      "Training input sequence length: 33\n",
      "Training target outputs sequence length: 2\n",
      "\n",
      "TEXT:\n",
      "delicious. i can not get australian ginger where i live. this compares favorably to australian ginger i 've purchased in other cities. now i can enjoy it without traveling.\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "burns food\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "happy face\n",
      "\n",
      "loss=13.0844\n",
      "\n",
      "Iteration: 84\n",
      "Training input sequence length: 30\n",
      "Training target outputs sequence length: 4\n",
      "\n",
      "TEXT:\n",
      "i keep trying other brands .... cheaper brands. stupid me! this ginger is soooo worth the money. tender, moist and never a let down.\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "me spicy me spicy\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "simply the best!\n",
      "\n",
      "loss=17.7593\n",
      "\n",
      "Iteration: 85\n",
      "Training input sequence length: 52\n",
      "Training target outputs sequence length: 2\n",
      "\n",
      "TEXT:\n",
      "i bought this for our office to give people something sweet to snack on. because it 's bite size it 's easier for people to grab a couple a pieces rather than an entire licorice stick. my only complaint is that one of the bags broke open in shipping.\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "me spicy\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACTUAL SUMMARY:\n",
      "\n",
      "nice snack\n",
      "\n",
      "loss=12.5705\n",
      "\n",
      "Iteration: 86\n",
      "Training input sequence length: 59\n",
      "Training target outputs sequence length: 2\n",
      "\n",
      "TEXT:\n",
      "twizzlers brand licorice is much better than that other well known unk< br/> if you can get these for$ 2 to$ 2.50 a package with free unk it 's a good unk< br/> the black and cherry have good taste; but the strawberry taste was too delicate and barely there\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "value favorite\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "good licorice\n",
      "\n",
      "loss=10.595\n",
      "\n",
      "Iteration: 87\n",
      "Training input sequence length: 36\n",
      "Training target outputs sequence length: 5\n",
      "\n",
      "TEXT:\n",
      "this is one of the best salsas that i have found in a long time but stay away from the variety pack. the other two that come with it are not worth your money.\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "& looks& looks&\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "love the salsa!!\n",
      "\n",
      "loss=12.9428\n",
      "\n",
      "Iteration: 88\n",
      "Training input sequence length: 44\n",
      "Training target outputs sequence length: 2\n",
      "\n",
      "TEXT:\n",
      "these remind me of dog treats i made once using pumpkin and cinnamon. they 're kind of bland and not my favorite back to nature product. but my unk really loves them so that 's where the three stars come from.\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "beautiful happy\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "unk ...\n",
      "\n",
      "loss=8.44148\n",
      "\n",
      "Iteration: 89\n",
      "Training input sequence length: 39\n",
      "Training target outputs sequence length: 2\n",
      "\n",
      "TEXT:\n",
      "this is the best cornmeal. i made regular cornbread and hot water cornbread with this meal and both were outstanding. also fried some oysters with this meal, it gave them a great texture and unk.\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "happy face\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "awesome cornmeal\n",
      "\n",
      "loss=9.24887\n",
      "\n",
      "Iteration: 90\n",
      "Training input sequence length: 64\n",
      "Training target outputs sequence length: 3\n",
      "\n",
      "TEXT:\n",
      "this is a fabulous marinade! i love to use it for chicken, either baked in the oven or on the grill. this has enough flavor& flair, i 've even used it for dinner parties, only to receive rave reviews from my guests!! definitely worth the price! super cheap and super easy! love it!\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "simply snack simply\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "great marinade!\n",
      "\n",
      "loss=8.59732\n",
      "\n",
      "Iteration: 91\n",
      "Training input sequence length: 29\n",
      "Training target outputs sequence length: 2\n",
      "\n",
      "TEXT:\n",
      "works with chicken fish beef or pork. fast easy and makes it taste excellent. plus buying in bulk is more than 50% off from box stores\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "snack nice\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "awesome stuff\n",
      "\n",
      "loss=5.34815\n",
      "\n",
      "Iteration: 92\n",
      "Training input sequence length: 25\n",
      "Training target outputs sequence length: 2\n",
      "\n",
      "TEXT:\n",
      "got this for my brother who is on jorge cruise diet and decided to try one for myself. it actually tastes pretty good.\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "awesome licorice\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "tastes good\n",
      "\n",
      "loss=20.5703\n",
      "\n",
      "Iteration: 93\n",
      "Training input sequence length: 54\n",
      "Training target outputs sequence length: 3\n",
      "\n",
      "TEXT:\n",
      "these singles sell for$ 2.50-$ 3.36 at the store for 1 box of 24 singles. i 'm not sure why amazon is selling it for$ 9.99 for a box of 24 singles. hazelnut coffee creamer is my favorite, but truly this is not a good buy.\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "licorice awesome licorice\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "rip off price\n",
      "\n",
      "loss=14.0714\n",
      "\n",
      "Iteration: 94\n",
      "Training input sequence length: 66\n",
      "Training target outputs sequence length: 1\n",
      "\n",
      "TEXT:\n",
      "awesome!!! such a yummy flavor i got it as a healthy alternative to the desserts we normally eat and i am so glad that i did there are so many things you can do with jello desserts and still have them taste good and be good for you. i will unk be purchasing this product again the flavor was so wonderful.\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "cornmeal\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "jell-o\n",
      "\n",
      "loss=12.6807\n",
      "\n",
      "Iteration: 95\n",
      "Training input sequence length: 37\n",
      "Training target outputs sequence length: 2\n",
      "\n",
      "TEXT:\n",
      "what a deal this is the healthiest salt you can use. this box should last our family the year no problem. iodized sea salt will not raise your blood pressure as regular salt will.\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "awesome cornmeal\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "great deal\n",
      "\n",
      "loss=16.0067\n",
      "\n",
      "Iteration: 96\n",
      "Training input sequence length: 25\n",
      "Training target outputs sequence length: 6\n",
      "\n",
      "TEXT:\n",
      "perfect size sea salt for the table or the picnic basket. we love it. shakes well, no clumping and flows freely.\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "... stuff ... stuff ... stuff\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "great tasting sea salt with iodine\n",
      "\n",
      "loss=14.8974\n",
      "\n",
      "Iteration: 97\n",
      "Training input sequence length: 48\n",
      "Training target outputs sequence length: 3\n",
      "\n",
      "TEXT:\n",
      "i 've never heard of the unk brand before but i was tired of only trying the typical pouches; starkist and chicken of the sea. i was really surprised as i thought it was a bit better than the other brands and with less seasoning.\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "stuff marinade stuff\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "simple but good\n",
      "\n",
      "loss=14.8796\n",
      "\n",
      "Iteration: 98\n",
      "Training input sequence length: 27\n",
      "Training target outputs sequence length: 2\n",
      "\n",
      "TEXT:\n",
      "these are the best tasting tuna pack they make in my opinion- make a great on the go snack, and really satisfying with the tomato\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "marinade stuff\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "tasty!\n",
      "\n",
      "loss=9.89895\n",
      "\n",
      "Iteration: 99\n",
      "Training input sequence length: 37\n",
      "Training target outputs sequence length: 4\n",
      "\n",
      "TEXT:\n",
      "i have always purchased unk tuna but thought i would try this brand for a change of pace. the taste of the tuna was not pleasant, too much basil and other spices for me.\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "off jell-o off jell-o\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "from __future__ import print_function\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "\n",
    "with tf.Session() as sess: # Start Tensorflow Session\n",
    "    \n",
    "    saver = tf.train.Saver() \n",
    "    # Prepares variable for saving the model\n",
    "    sess.run(init) #initialize all variables\n",
    "    step = 0   \n",
    "    loss_list=[]\n",
    "    acc_list=[]\n",
    "    val_loss_list=[]\n",
    "    val_acc_list=[]\n",
    "    best_val_acc=0\n",
    "    display_step = 1\n",
    "    \n",
    "    while step < training_iters:\n",
    "        \n",
    "        total_loss=0\n",
    "        total_acc=0\n",
    "        total_val_loss = 0\n",
    "        total_val_acc = 0\n",
    "           \n",
    "        for i in xrange(0,train_len):\n",
    "            \n",
    "            train_out = transform_out(train_summaries[i][0:len(train_summaries[i])-1])\n",
    "            \n",
    "            if i%display_step==0:\n",
    "                print(\"\\nIteration: \"+str(i))\n",
    "                print(\"Training input sequence length: \"+str(len(train_texts[i])))\n",
    "                print(\"Training target outputs sequence length: \"+str(len(train_out)))\n",
    "            \n",
    "                print(\"\\nTEXT:\")\n",
    "                flag = 0\n",
    "                for vec in train_texts[i]:\n",
    "                    if vec2word(vec) in string.punctuation or flag==0:\n",
    "                        print(str(vec2word(vec)),end='')\n",
    "                    else:\n",
    "                        print((\" \"+str(vec2word(vec))),end='')\n",
    "                    flag=1\n",
    "\n",
    "                print(\"\\n\")\n",
    "\n",
    "\n",
    "            # Run optimization operation (backpropagation)\n",
    "            _,loss,pred = sess.run([optimizer,cost,prediction],feed_dict={tf_text: train_texts[i], \n",
    "                                                    tf_seq_len: len(train_texts[i]), \n",
    "                                                    tf_summary: train_out,\n",
    "                                                    tf_output_len: len(train_out)})\n",
    "            \n",
    "         \n",
    "            if i%display_step==0:\n",
    "                print(\"\\nPREDICTED SUMMARY:\\n\")\n",
    "                flag = 0\n",
    "                for index in pred:\n",
    "                    #if int(index)!=vocab_limit.index('eos'):\n",
    "                    if vocab_limit[int(index)] in string.punctuation or flag==0:\n",
    "                        print(str(vocab_limit[int(index)]),end='')\n",
    "                    else:\n",
    "                        print(\" \"+str(vocab_limit[int(index)]),end='')\n",
    "                    flag=1\n",
    "                print(\"\\n\")\n",
    "                \n",
    "                print(\"ACTUAL SUMMARY:\\n\")\n",
    "                flag = 0\n",
    "                for vec in train_summaries[i]:\n",
    "                    if vec2word(vec)!='eos':\n",
    "                        if vec2word(vec) in string.punctuation or flag==0:\n",
    "                            print(str(vec2word(vec)),end='')\n",
    "                        else:\n",
    "                            print((\" \"+str(vec2word(vec))),end='')\n",
    "                    flag=1\n",
    "\n",
    "                print(\"\\n\")\n",
    "            \n",
    "                #print(hs)\n",
    "            \n",
    "                print(\"loss=\"+str(loss))\n",
    "            \n",
    "            #print(h)\n",
    "            #print(out)\n",
    "            #print(ht_s)\n",
    "            \n",
    "        step=step+1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
